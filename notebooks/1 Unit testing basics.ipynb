{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Unit testing basics\n",
    "In this chapter, you will get introduced to the pytest package and use it to write simple unit tests. You'll run the tests, interpret the test result reports and fix bugs. Throughout the chapter, we will use examples exclusively from the data preprocessing module of a linear regression project, making sure you learn unit testing in the context of data science."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Manual testing\n",
    "The function row_to_list(), which you met in the video lesson, has the following expected return values for the arguments listed below.\n",
    "\n",
    "\n",
    "| Argument       | Expected return value  | Explanation    |\n",
    "| :------------- | :----------: | -----------: |\n",
    "|  \"2,081\\t314,942\\n\" | [\"2,081\", \"314,942\"]   | Correct row format    |\n",
    "| \"\\t293,410\\n\"  | None | Missing area|\n",
    "| \"1,463238,765\\n\" | None | Missing tab separator|\n",
    "\n",
    "\n",
    "row_to_list() has been defined and imported for you. Your job is to test the function manually in the IPython console.\n",
    "\n",
    "While testing manually, notice how many times you have to repeat the same steps! The point is to experience the inefficiency of manual testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def row_to_list(row):\n",
    "    row = row.rstrip()\n",
    "    separated_entries = row.split(\"\\t\")\n",
    "    if len(separated_entries) == 2:\n",
    "        return separated_entries\n",
    "    return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question\n",
    "Call row_to_list() in the IPython console on the three arguments listed in the table. Do the actual return values match the expected return values listed in the table?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['2,081', '314,942']\n",
      "['', '293,410']\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(row_to_list(\"2,081\\t314,942\\n\"))\n",
    "print(row_to_list(\"\\t293,410\\n\"))\n",
    "print(row_to_list(\"1,463238,765\\n\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No. the function returns [\"\", \"293,410\"] for the argument \"\\t293,410\\n\" instead of the expected return value None."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def row_to_list_bugfix(row):\n",
    "    row = row.rstrip()\n",
    "    separated_entries = row.split(\"\\t\")\n",
    "    if len(separated_entries) == 2 and \"\" not in separated_entries:\n",
    "        return separated_entries    \n",
    "    return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the last step, you discovered a bug in our implementation of row_to_list(). Good job!\n",
    "\n",
    "We have implemented a corresponding bug fix in a new function row_to_list_bugfix(). Call row_to_list_bugfix() in the IPython console on the three arguments listed in the table. Do the actual return values now match the expected return values listed in the table?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['2,081', '314,942']\n",
      "None\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(row_to_list_bugfix(\"2,081\\t314,942\\n\"))\n",
    "print(row_to_list_bugfix(\"\\t293,410\\n\"))\n",
    "print(row_to_list_bugfix(\"1,463238,765\\n\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Yes, the implementation returns the expected value in each case."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Well done! Did you notice how manual testing involves repeating the same steps over and over in the IPython console? In this exercise, you just went through a single bug discovery and fixing phase. Just imagine doing this a hundred times over the entire life cycle of row_to_list(), including new feature implementation and refactoring phases! Unit testing can automate these repetitive steps, so that testing becomes easier, and you will learn it in the next lesson ;-)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Your first unit test using pytest\n",
    "The data file containing housing area and prices uses commas as thousands separators, e.g. \"2,081\" or \"314,942\", as you can see in the IPython Shell.\n",
    "\n",
    "The convert_to_int() function takes a comma separated integer string as argument, and returns the integer. Therefore, the expected return value of convert_to_int(\"2,081\") is the integer 2081.\n",
    "\n",
    "This function is defined in the module preprocessing_helpers.py. But it is not known if the function is working properly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_int(number_with_commas):\n",
    "    return number_with_commas.replace(\",\", \"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the pytest package\n",
    "import pytest\n",
    "\n",
    "# Import the function convert_to_int()\n",
    "from utils.preprocessing_helpers import convert_to_int\n",
    "\n",
    "# Complete the unit test name by adding a prefix\n",
    "def test_on_string_with_one_comma():\n",
    "  # Complete the assert statement\n",
    "  assert convert_to_int(\"2,081\") == 2081"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You just wrote your first unit test using pytest. Congratulations! A unit test takes 5 minutes to write, but saves you many hours in the future."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running unit tests\n",
    "The tests that you wrote in the previous exercise have been written to a test module test_convert_to_int.py. Try running the tests in the IPython console.\n",
    "\n",
    "What is the correct IPython console command to run the tests in this test module?`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m============================= test session starts ==============================\u001B[0m\n",
      "platform darwin -- Python 3.9.1, pytest-5.2.2, py-1.10.0, pluggy-0.13.1\n",
      "Matplotlib: 3.1.1\n",
      "Freetype: 2.10.2\n",
      "rootdir: /Users/alejandro.robles/PycharmProjects/unit-testing-for-data-science-in-python\n",
      "plugins: mock-1.11.2, mpl-0.10\n",
      "collected 1 item                                                               \u001B[0m\n",
      "\n",
      "utils/test_convert_to_int.py \u001B[31mF\u001B[0m\u001B[36m                                           [100%]\u001B[0m\n",
      "\n",
      "=================================== FAILURES ===================================\n",
      "\u001B[31m\u001B[1m________________________ test_on_string_with_one_comma _________________________\u001B[0m\n",
      "\n",
      "\u001B[1m    def test_on_string_with_one_comma():\u001B[0m\n",
      "\u001B[1m>     assert convert_to_int(\"2,081\") == 2081\u001B[0m\n",
      "\u001B[1m\u001B[31mE     AssertionError: assert '2081' == 2081\u001B[0m\n",
      "\u001B[1m\u001B[31mE      +  where '2081' = convert_to_int('2,081')\u001B[0m\n",
      "\n",
      "\u001B[1m\u001B[31mutils/test_convert_to_int.py\u001B[0m:10: AssertionError\n",
      "\u001B[31m\u001B[1m============================== 1 failed in 0.18s ===============================\u001B[0m\n"
     ]
    }
   ],
   "source": [
    "!pytest utils/test_convert_to_int.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Congratulations! You just wrote and ran your first unit test. You probably saw that running the test produced a lot of output. This output contains information about a bug in convert_to_int(). You should be able to read and understand this output in order to bug fix efficiently. This will be covered in the next video lesson. Jump right in!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What causes a unit test to fail?\n",
    "In the test result report, the character ., as shown below, stands for a passing test. A passing test is good news as it means that your function works as expected. The character F stands for a failing test. A failing test is bad news as this means that something is broken.\n",
    "\n",
    "test_row_to_list.py .F.                                                  [100%]\n",
    "Which of the following describes best why a unit test fails?\n",
    "\n",
    "### Answer: \n",
    "An exception is raised when running the unit test. This could be an AssertionError raised by the assert statement or another exception, e.g. NameError, which is raised before the assert statement can run.\n",
    "\n",
    "Exactly! If you get an AssertionError, this means the function has a bug and you should fix it. If you get another exception, e.g. NameError, this means that something else is wrong with the unit test code and you should fix it so that the assert statement can actually run."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Spotting and fixing bugs\n",
    "To find bugs in functions, you need to follow a four step procedure.\n",
    "\n",
    "1. Write unit tests.\n",
    "2. Run them.\n",
    "3. Read the test result report and spot the bugs.\n",
    "4. Fix the bugs.\n",
    "\n",
    "In a previous exercise, you wrote a unit test for the function convert_to_int(), which is supposed to convert a comma separated integer string like \"2,081\" to the integer 2081. You also ran the unit test and discovered that it is failing.\n",
    "\n",
    "In this exercise, you will read the test result report from that exercise in detail, and then spot and fix the bug. This would equip you with all basic skills to start using unit tests for your projects.\n",
    "\n",
    "The convert_to_int() function is defined in the file preprocessing_helpers.py. The unit test is available in the test module test_convert_to_int.py.\n",
    "\n",
    "## Question\n",
    "Run the unit test in the test module test_convert_to_int.py in the IPython console. Read the test result report and spot the bug.\n",
    "\n",
    "Which of the following describes the bug in the function convert_to_int(), if any?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m============================= test session starts ==============================\u001B[0m\n",
      "platform darwin -- Python 3.9.1, pytest-5.2.2, py-1.10.0, pluggy-0.13.1\n",
      "Matplotlib: 3.1.1\n",
      "Freetype: 2.10.2\n",
      "rootdir: /Users/alejandro.robles/PycharmProjects/unit-testing-for-data-science-in-python\n",
      "plugins: mock-1.11.2, mpl-0.10\n",
      "collected 1 item                                                               \u001B[0m\n",
      "\n",
      "utils/test_convert_to_int.py \u001B[31mF\u001B[0m\u001B[36m                                           [100%]\u001B[0m\n",
      "\n",
      "=================================== FAILURES ===================================\n",
      "\u001B[31m\u001B[1m________________________ test_on_string_with_one_comma _________________________\u001B[0m\n",
      "\n",
      "\u001B[1m    def test_on_string_with_one_comma():\u001B[0m\n",
      "\u001B[1m>     assert convert_to_int(\"2,081\") == 2081\u001B[0m\n",
      "\u001B[1m\u001B[31mE     AssertionError: assert '2081' == 2081\u001B[0m\n",
      "\u001B[1m\u001B[31mE      +  where '2081' = convert_to_int('2,081')\u001B[0m\n",
      "\n",
      "\u001B[1m\u001B[31mutils/test_convert_to_int.py\u001B[0m:10: AssertionError\n",
      "\u001B[31m\u001B[1m============================== 1 failed in 0.18s ===============================\u001B[0m\n"
     ]
    }
   ],
   "source": [
    "!pytest utils/test_convert_to_int.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "convert_to_int(\"2,081\") is expected to return the integer 2081, but it is actually returning the string \"2081\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fix the convert_to_int() function so that it returns the integer 2081 instead of the string \"2081\" for the argument \"2,081\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_int(string_with_comma):\n",
    "    # Fix this line so that it returns an int, not a str\n",
    "    return int(string_with_comma.replace(\",\", \"\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Good work! Your boss and colleagues are going to really appreciate your new skill of reading test result reports, and then spotting and fixing the bugs, because this would mean fewer bugs in the code base in the long term."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Unit tests as documentation\n",
    "Assume that you are a new collaborator of our linear regression project on housing area and prices.\n",
    "\n",
    "While inspecting the project, you come across a function mystery_function() in the feature module. You want to figure out what this function does. As you know, reading the unit tests might give you the answer quickly!\n",
    "\n",
    "The unit tests for the function is available in the test module test_mystery_function.py. You can read it, and any other file that you encounter, by using the !cat command in the IPython shell.\n",
    "\n",
    "Having read the unit tests, can you guess what mystery_function() does?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "import numpy as np\r\n",
      "import pytest\r\n",
      "\r\n",
      "from mystery_function import mystery_function\r\n",
      "\r\n",
      "def test_on_clean_data():\r\n",
      "    assert np.array_equal(mystery_function(\"example_clean_data.txt\", num_columns=2), np.array([[2081.0, 314942.0], [1059.0, 186606.0]]))"
     ]
    }
   ],
   "source": [
    "!cat utils/test_mystery_function.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It converts data in a data file into a NumPy array.\n",
    "\n",
    "You guessed it right and you didn't even take a look at the function definition! This is why - when onboarding new colleagues - it is a good idea to tell them to look at the unit tests if they are not sure about a function's purpose. In Chapter 2, you will see more functions from the feature and models module, and write more advanced unit tests using new pytest features."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}